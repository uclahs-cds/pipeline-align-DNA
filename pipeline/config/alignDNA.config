manifest {
    name = "alignDNA"
    author = "Benjamin Carlin"
    description = "alignment pipeline for paired fastqs DNA samples"
    version = "1.0"
}

params {
    // sample files
    input_csv = "path/to/input/csv/"
    reference_fasta = "/path/to/fasta/"
    reference_fasta_dict = "/path/to/fasta/dict"
    reference_fasta_index_files = "/path/to/fasta/index/files"

    // input/output locations
    output_dir = "where/to/save/outputs/"
    java_temp_dir = "java/temp/file/dir/"
    temp_dir = "local/disk/temp/file/dir/"

    // option
    save_intermediate_files = false

    // resource configuraton for entire pipeline
    max_number_of_parallel_jobs = 2
    max_number_of_cpus = 64
    max_memory = "140 GB"

    // max # of cpus for alignment with BWA mem (same process as SAMTools convert)
    number_of_cpus_for_BWA_mem = 48

    // max # of cpus for Sam to Bam conversion with SAMTools (same process as BWA mem)
    number_of_cpus_for_SAMTools_Convert_Sam_to_Bam = 16

    // max amount of memory for alignment and Sam to Bam conversion process
    memory_for_BWA_mem_SAMTools_Convert_Sam_to_Bam = "140 GB"

    // resource configuration for PicardTools processes
    number_of_cpus_for_PicardTools = 64
    memory_for_PicardTools = "140 GB"
}

// location of Nextflow temp directories  
workDir = params.temp_dir
NXF_WORK = params.temp_dir
NXF_TEMP = params.temp_dir
NXF_HOME = params.temp_dir

process {
    // monitor process jobs with local (not slurm) executor
    executor = "local"

    // total amount of resources avaible to the pipeline
    maxForks = params.max_number_of_parallel_jobs
    cpus = params.max_number_of_cpus
    memory = params.max_memory

    // amount of resources avaible for BWA and SAMTools (they are in the same process)
    withLabel: resource_allocation_for_BWA_mem_SAMTools_Convert_Sam_to_Bam {
        cpus = params.number_of_cpus_for_BWA_mem + params.number_of_cpus_for_SAMTools_Convert_Sam_to_Bam
        memory = params.memory_for_BWA_mem_SAMTools_Convert_Sam_to_Bam
    }

    // amount of resources avaible for PicardTools
    withLabel: resource_allocation_for_PicardTools {
        cpus = params.number_of_cpus_for_PicardTools
        memory = params.memory_for_PicardTools
    }

    // do not cache intermediate steps and echo stdout of each step to stdout of pipeline
    echo = true
    cache = false
}

docker {
    enabled = true
}

// pipeline monitoring and metric files
timeline {
    enabled = true
    file = "${params.output_dir}/timeline.html"
}

trace {
    enabled = true
    file = "${params.output_dir}/trace.txt"
}

report {
    enabled = true
    file = "${params.output_dir}/report.html"
}
