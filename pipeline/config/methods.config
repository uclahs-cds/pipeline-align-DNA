import java.util.TimeZone
import nextflow.util.SysHelper

methods {

    // IS CHECK_PERMISSIONS REPLACEABLE WITH CHECK_WORKDIR_PERMISSIONS?

    // This code differs substantially from template check_workdir_permissions, can it be changed?
    check_permissions = { path ->
        def filePath = new File(path)

        if (filePath.exists()) {
            if (filePath.canWrite()) {
                return
                }
            throw new Exception("${path} is not writable")
            }

        // Attempts to create directory if the path does not exist
        if (!filePath.mkdirs()) {
            throw new Exception("${path} does not exist and could not create")
            }
        }

    /**
     * Check the permissions and existence of workDir.
     * If it doesn't exist, recursively find first existing directory and check write permission.
     * If it exists, check write permission.
     */
    check_workdir_permissions = { dir ->
        dir_file = new File(dir)
        if (dir_file.exists()) {
            if (dir_file.canWrite()) {
                return true
            } else {
                throw new Exception("   ### ERROR ###   The input directory params.work_dir: ${dir} is not writeable. Please verify and try again.")
            }
        } else {
            while (!dir_file.exists()) {
                dir_file = dir_file.getParentFile()
            }

            if (dir_file.canWrite()) {
                return true
            } else {
                throw new Exception("   ### ERROR ###   The input directory params.work_dir: ${dir} cannot be created. The closest existing parent directory ${dir_file.toString()} is not writable. Please verify permissions or change the input parameter.")
            }
        }
    }

    check_aligner = {

        if (!params.containsKey('aligner')) {
            params.aligner = ["BWA-MEM2"]
            params.reference_fasta_bwa = params.reference_fasta
            params.reference_fasta_index_files_bwa = "${params.reference_fasta_bwa}.*"
            if (!params.containsKey('reference_fasta_index_files_bwa')) {
                params.reference_fasta_index_files_bwa = "${params.reference_fasta_bwa}.fai"
                }
            }
        else {
        if (params.aligner.contains("BWA-MEM2")) {
            if (!params.containsKey('reference_fasta_index_files_bwa')) {
                params.reference_fasta_index_files_bwa = "${params.reference_fasta_bwa}.*"
                }
            if (!params.containsKey('reference_fasta_index_files_bwa')) {
                params.reference_fasta_index_files_bwa = "${params.reference_fasta_bwa}.fai"
                }   
            }

        if (params.aligner.contains('HISAT2')) {
            params.reference_fasta_index_files_hisat2 = "${params.hisat2_index_prefix}.*.ht2"
            }
        }
    }

    // Set the output directory and filename for output bam and log files. If the input dataset is
    // registered in the blcdes, the output directory is set to the data storage. Otherwise, the
    // ouput directory is set to the params.output_dir
    set_output_dir = {
        // if the fastq files from inpu.csv are registered blcds datasets, dataset information is
        // read from the fastq path, including disease_id, dataset_id, patient_id, and sample_id.
        if (params.blcds_registered_dataset_input) {
            def fastqs = []
            def reader = new FileReader(params.input_csv)
            reader.splitEachLine(",") { fields ->
                fastqs.add(fields[8])
                }
            fastqs.removeAt(0)
            def pattern = ~/^(?<baseDir>(?<mntDir>\/\w+)\/data\/(?<diseaseId>\w+)\/(?<datasetId>\w+)\/(?<patientId>\w+)\/(?<sampleId>[A-Za-z0-9-]+)\/(?<analyte>.+)\/(?<technology>.+))\/raw\/FASTQ\/.+$/
            
            // First check if all input fastq files are from the same sample_id
            base_dirs = fastqs.collect {
                def matcher = it =~ pattern
                if (!matcher.matches()) {
                    throw new Exception("The input path ${it} isn't a valid blcds-registered path.")
                    }
                return matcher.group("baseDir")
                }
            .unique(false)

            if (base_dirs.size() > 1) {
                throw new Exception(
                    "Not all input fastq files are from the same blcds-registered sample.\n" +
                    "Please verify."
                    )
                }

            // grep sample informations from input path
            def matcher = fastqs[0] =~ pattern
            matcher.matches()
            def base_dir = matcher.group("baseDir")

            params.blcds_disease_id = matcher.group("diseaseId")
            params.blcds_dataset_id = matcher.group("datasetId")
            params.blcds_patient_id = matcher.group("patientId")
            params.blcds_sample_id  = matcher.group("sampleId")
            params.blcds_mount_dir  = matcher.group("mntDir")
            params.blcds_analyte    = matcher.group("analyte")
            params.blcds_technology = matcher.group("technology")
            if (!(new File(params.blcds_mount_dir).exists())) {
                throw new Exception(
                    "The mount directory \"${params.blcds_mount_dir}\" was not found.\n" +
                    "Please double check the input.csv: ${params.input_csv} "
                    )
                }
        } else if (params.blcds_registered_dataset_output) {
            // TODO: need to valid dataset information
            if (!params.containsKey("blcds_disease_id") || !params.containsKey("blcds_dataset_id") ||
                !params.containsKey("blcds_patient_id") || !params.containsKey("blcds_sample_id") ||
                !params.containsKey("blcds_analyte") || !params.containsKey("blcds_technology")) {
                throw new Exception(
                    "Please specify the disease_id, patient_id, dataset_id, sample_id, analyte, " +
                    "and technology in the config file."
                    )
                }
            if (!params.containsKey("blcds_mount_dir")) {
                if (!params.containsKey("blcds_cluster_slurm")) {
                    throw new Exception(
                        "Please specify either the `params.blcds_cluster_slurm` or " +
                        "`params.blcds_mount_dir`"
                        )
                    }
                params.blcds_mount_dir = params.blcds_cluster_slurm ? "/hot" : "/data"   
                }
            if (!(new File(params.blcds_mount_dir).exists())) {
                throw new Exception(
                    "The mount directory \"${params.blcds_mount_dir}\" does not exist.\n" +
                    "Please verify the config file."
                    )
                }
            }

        // set output directly accordingly
        def tz = TimeZone.getTimeZone("UTC")
        def date = new Date().format("yyyyMMdd'T'HHmmss'Z'", tz)
        if (params.blcds_registered_dataset_output) {
            def base_dir = "${params.blcds_mount_dir}/data/${params.blcds_disease_id}/${params.blcds_dataset_id}/${params.blcds_patient_id}/${params.blcds_sample_id}/${params.blcds_analyte}/${params.blcds_technology}"
            // using pasific timezone
            if (!(new File(base_dir).canWrite())) {
                throw new Exception(
                    "No permission to write ${base_dir}\n"
                    )
                }
            params.bam_output_dir = "${base_dir}/aligned/${params.reference_genome_version}/${params.bwa_version.toUpperCase()}/BAM"
            params.bam_output_filename = "${params.bwa_version.toUpperCase()}_${params.blcds_dataset_id}_${params.blcds_sample_id}.bam"
            params.log_output_dir = "${params.bam_output_dir}/log/align-DNA-${date}"
        } else {
            params.base_output_dir = "${params.output_dir}/${manifest.name}-${manifest.version}/${params.sample_name}"
            params.bam_output_filename = "${params.sample_name}.bam"
            params.log_output_dir = "${params.base_output_dir}/log-${manifest.name}-${manifest.version}-$date/"
            }

        methods.check_permissions(params.log_output_dir)
    }

    // Function to ensure that resource requirements don't go beyond
    // a maximum limit
    check_max = { obj, type ->
        if (type == 'memory') {
            try {
                if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                    return params.max_memory as nextflow.util.MemoryUnit
                else
                    return obj
            } catch (all) {
                println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
                return obj
            }
        } else if (type == 'time') {
            try {
                if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                    return params.max_time as nextflow.util.Duration
                else
                    return obj
            } catch (all) {
                println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
                return obj
            }
        } else if (type == 'cpus') {
            try {
                return Math.min(obj, params.max_cpus as int)
            } catch (all) {
                println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
                return obj
            }
        }
    }

    // Resource allocation here. Static node-based allocations included here
    set_resources_allocation = {
        // Function to ensure that resource requirements don't go beyond
        // a maximum limit        
        node_cpus = params.max_cpus
        node_memory_GB = params.max_memory.toGiga()
        // Load base.config by default for all pipelines
        includeConfig "${projectDir}/config/base.config"
        if (params.ucla_cds) {
            if (node_cpus == 64) {
                // Check memory for M64 node
                if (node_cpus == 64 && node_memory_GB >= 950 && node_memory_GB <= 1010) {
                    includeConfig "${projectDir}/config/M64.config"
                } else {
                    throw new Exception("   ### ERROR ###   System resources not as expected (cpus=${node_cpus} memory=${node_memory_GB}), unable to assign resources.")
                }
            } else {
                // Check memory for F series node
                if (node_memory_GB >= (node_cpus * 2 * 0.9) && node_memory_GB <= (node_cpus * 2)) {
                    includeConfig "${projectDir}/config/F${node_cpus}.config"
                } else {
                    throw new Exception("   ### ERROR ###   System resources not as expected (cpus=${node_cpus} memory=${node_memory_GB}), unable to assign resources.")
                }
            }
        }
    }

    set_env = {
        if (params.ucla_cds) {
            /**
             * By default, if the /scratch directory exists, set it as the Nextflow working directory
             * If config file specified work_dir, set it as the Nextflow working directory
             * 
             * WARNING: changing this directory can lead to high server latency and
             * potential disk space limitations. Change with caution! The 'workDir'
             * in Nextflow determines the location of intermediate and temporary files.
             */
            params.work_dir = (params.containsKey('work_dir') && params.work_dir) ? params.work_dir : '/scratch'
            if (methods.check_workdir_permissions(params.work_dir)) {
                workDir = params.work_dir
            }
        } else {
            // If work_dir was specified as a param and exists or can be created, set workDir. Otherwise, let Nextflow's default behavior dictate workDir
            if (params.containsKey('work_dir') && params.work_dir && methods.check_workdir_permissions(params.work_dir)) {
                workDir = params.work_dir
            }
        }
    }

    set_pipeline_logs = {
        trace.enabled = true
        trace.file = "${params.log_output_dir}/nextflow-log/trace.txt"

        timeline.enabled = true
        timeline.file = "${params.log_output_dir}/nextflow-log/timeline.html"
        
        report.enabled = true
        report.file = "${params.log_output_dir}/nextflow-log/report.html"
    }

    // Do we still need this?
    set_docker_sudo = {
        if (params.containsKey("blcds_cluster_slurm") && (!params.blcds_cluster_slurm)) {
            docker.sudo = true
            }
        if (params.containsKey("blcds_mount_dir") && (params.blcds_mount_dir == '/data')) {
            docker.sudo = true
            }
        }

    setup = {
        methods.set_output_dir()
        methods.set_env()
        methods.set_pipeline_logs()
        methods.set_docker_sudo()
        methods.check_aligner()
        methods.set_resources_allocation()

        // Do we want to keep this? Not sure if it's still compatible with set_resources_allocation()
        if (!params.containsKey('check_node_config') || params.check_node_config) {
            methods.set_resources_allocation()
            }
        else {
            System.out.println "WARNING: check_node_config is false. This job will not configure process CPU and memory parameters, which may cause unexpected run times."
            }
        }
    }
