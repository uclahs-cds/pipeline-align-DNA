import java.util.TimeZone
import nextflow.util.SysHelper

manifest {
    name = "align-DNA"
    author = "Benjamin Carlin; Chenghao Zhu; Aaron Holmes"
    description = "alignment pipeline for paired fastqs DNA samples"
    version = "7.1.0"
    }

params {
    // resource configuraton for entire pipeline
    // max_number_of_parallel_jobs = 1

    // tools and their versions
    bwa_version = "BWA-MEM2-2.2.1"
    hisat2_version = "HISAT2-2.2.1"

    docker_image_bwa_and_samtools = "blcdsdockerregistry/bwa-mem2_samtools-1.12:2.2.1"
    docker_image_hisat2_and_samtools = "blcdsdockerregistry/hisat2_samtools-1.12:2.2.1"
    docker_image_picardtools = "blcdsdockerregistry/align-dna:picardtools-2.23.3"
    docker_image_sha512sum = "blcdsdockerregistry/align-dna:sha512sum-1.0"
    docker_image_validate_params = "blcdsdockerregistry/validate:2.1.5"    
    docker_image_gatk = "broadinstitute/gatk:4.2.2.0"
    }

if (!params.containsKey('check_node_config')) {
    // Set to false for testing on nodes that don't match the
    // pre-configured lowmem/midmem/execute nodes.
    // Removing this variable has the same effect as setting it to `true`.
    params.check_node_config = true
    }

if (!params.containsKey('aligner')) {
    params.aligner = ["BWA-MEM2"]
    params.reference_fasta_bwa = params.reference_fasta
    params.reference_fasta_index_files_bwa = "${params.reference_fasta_bwa}.*"
    if (!params.containsKey('reference_fasta_index_files_bwa')) {
        params.reference_fasta_index_files_bwa = "${params.reference_fasta_bwa}.fai"
        }
    }
else {
   if (params.aligner.contains("BWA-MEM2")) {
       if (!params.containsKey('reference_fasta_index_files_bwa')) {
           params.reference_fasta_index_files_bwa = "${params.reference_fasta_bwa}.*"
           }
       if (!params.containsKey('reference_fasta_index_files_bwa')) {
           params.reference_fasta_index_files_bwa = "${params.reference_fasta_bwa}.fai"
           }   
       }

   if (params.aligner.contains('HISAT2')) {
       params.reference_fasta_index_files_hisat2 = "${params.hisat2_index_prefix}.*.ht2"
       }
   }
    
params.mem_command_sort_sam = "4g"
params.mem_command_mark_duplicates = "4g"
params.mem_command_build_bam_index = "4g"

docker {
    _uid_and_gid = "-u \$(id -u):\$(id -g)"
    _all_group_ids = "\$(for i in `id --real --groups`; do echo -n \"--group-add=\$i \"; done)"

    enabled = true
    sudo = false
    runOptions = "${docker._uid_and_gid} ${docker._all_group_ids}"
    }

methods {
    check_permissions = { path ->
        def filePath = new File(path)

        if (filePath.exists()) {
            if (filePath.canWrite()) {
                return
                }
            throw new Exception("${path} is not writable")
            }

        // Attempts to create directory if the path does not exist
        if (!filePath.mkdirs()) {
            throw new Exception("${path} does not exist and could not create")
            }
        }

    // Set the output directory and filename for output bam and log files. If the input dataset is
    // registered in the blcdes, the output directory is set to the data storage. Otherwise, the
    // ouput directory is set to the params.output_dir
    set_output_dir = {
        // if the fastq files from inpu.csv are registered blcds datasets, dataset information is
        // read from the fastq path, including disease_id, dataset_id, patient_id, and sample_id.
        if (params.blcds_registered_dataset_input) {
            def fastqs = []
            def reader = new FileReader(params.input_csv)
            reader.splitEachLine(",") { fields ->
                fastqs.add(fields[8])
                }
            fastqs.removeAt(0)
            def pattern = ~/^(?<baseDir>(?<mntDir>\/\w+)\/data\/(?<diseaseId>\w+)\/(?<datasetId>\w+)\/(?<patientId>\w+)\/(?<sampleId>[A-Za-z0-9-]+)\/(?<analyte>.+)\/(?<technology>.+))\/raw\/FASTQ\/.+$/
            
            // First check if all input fastq files are from the same sample_id
            base_dirs = fastqs.collect {
                def matcher = it =~ pattern
                if (!matcher.matches()) {
                    throw new Exception("The input path ${it} isn't a valid blcds-registered path.")
                    }
                return matcher.group("baseDir")
                }
            .unique(false)

            if (base_dirs.size() > 1) {
                throw new Exception(
                    "Not all input fastq files are from the same blcds-registered sample.\n" +
                    "Please verify."
                    )
                }

            // grep sample informations from input path
            def matcher = fastqs[0] =~ pattern
            matcher.matches()
            def base_dir = matcher.group("baseDir")

            params.blcds_disease_id = matcher.group("diseaseId")
            params.blcds_dataset_id = matcher.group("datasetId")
            params.blcds_patient_id = matcher.group("patientId")
            params.blcds_sample_id  = matcher.group("sampleId")
            params.blcds_mount_dir  = matcher.group("mntDir")
            params.blcds_analyte    = matcher.group("analyte")
            params.blcds_technology = matcher.group("technology")
            if (!(new File(params.blcds_mount_dir).exists())) {
                throw new Exception(
                    "The mount directory \"${params.blcds_mount_dir}\" was not found.\n" +
                    "Please double check the input.csv: ${params.input_csv} "
                    )
                }
        } else if (params.blcds_registered_dataset_output) {
            // TODO: need to valid dataset information
            if (!params.containsKey("blcds_disease_id") || !params.containsKey("blcds_dataset_id") ||
                !params.containsKey("blcds_patient_id") || !params.containsKey("blcds_sample_id") ||
                !params.containsKey("blcds_analyte") || !params.containsKey("blcds_technology")) {
                throw new Exception(
                    "Please specify the disease_id, patient_id, dataset_id, sample_id, analyte, " +
                    "and technology in the config file."
                    )
                }
            if (!params.containsKey("blcds_mount_dir")) {
                if (!params.containsKey("blcds_cluster_slurm")) {
                    throw new Exception(
                        "Please specify either the `params.blcds_cluster_slurm` or " +
                        "`params.blcds_mount_dir`"
                        )
                    }
                params.blcds_mount_dir = params.blcds_cluster_slurm ? "/hot" : "/data"   
                }
            if (!(new File(params.blcds_mount_dir).exists())) {
                throw new Exception(
                    "The mount directory \"${params.blcds_mount_dir}\" does not exist.\n" +
                    "Please verify the config file."
                    )
                }
            }

        // set output directly accordingly
        def tz = TimeZone.getTimeZone("PST")
        def date = new Date().format('yyyyMMdd-HHmmss', tz)
        if (params.blcds_registered_dataset_output) {
            def base_dir = "${params.blcds_mount_dir}/data/${params.blcds_disease_id}/${params.blcds_dataset_id}/${params.blcds_patient_id}/${params.blcds_sample_id}/${params.blcds_analyte}/${params.blcds_technology}"
            // using pasific timezone
            if (!(new File(base_dir).canWrite())) {
                throw new Exception(
                    "No permission to write ${base_dir}\n"
                    )
                }
            params.bam_output_dir = "${base_dir}/aligned/${params.reference_genome_version}/${params.bwa_version.toUpperCase()}/BAM"
            params.bam_output_filename = "${params.bwa_version.toUpperCase()}_${params.blcds_dataset_id}_${params.blcds_sample_id}.bam"
            params.log_output_dir = "${params.bam_output_dir}/log/align-DNA-${date}"
        } else {
            params.bam_output_dir = "${params.output_dir}/align-DNA-${date}"
            params.bam_output_filename = "${params.sample_name}.bam"
            params.log_output_dir = "${params.output_dir}/align-DNA-${date}/log"
            }

        methods.check_permissions(params.log_output_dir)
    }

    set_env = {
        // location of Nextflow temp directories  
        workDir = params.temp_dir
        NXF_WORK = params.temp_dir
        NXF_TEMP = params.temp_dir
        NXF_HOME = params.temp_dir
        }

    set_timeline = {
        timeline.enabled = true
        timeline.file = "${params.log_output_dir}/timeline.html"
        }

    set_trace = {
        trace.enabled = true
        trace.file = "${params.log_output_dir}/trace.txt"
        }

    set_report = {
        report.enabled = true
        report.file = "${params.log_output_dir}/report.html"
        }

    set_process = {
        // monitor process jobs with local (not slurm) executor
        process.executor = "local"
        // total amount of resources avaible to the pipeline
        // process.maxForks = params.max_number_of_parallel_jobs
        // echo stdout of each step to stdout of pipeline
        process.echo = true
        process.cache = params.cache_intermediate_pipeline_steps
        }

    set_docker_sudo = {
        if (params.containsKey("blcds_cluster_slurm") && (!params.blcds_cluster_slurm)) {
            docker.sudo = true
            }
        if (params.containsKey("blcds_mount_dir") && (params.blcds_mount_dir == '/data')) {
            docker.sudo = true
            }
        }

    set_node_config = {
        def node_cpus = SysHelper.getAvailCpus()
        def node_mem  = SysHelper.getAvailMemory().toString()

        if (node_cpus == 2 && (node_mem == '3 GB' || node_mem == '3.9 GB')) {
            throw new Exception('ERROR: lowmem cannot be used for align-DNA.')
            }
        else if (node_cpus == 72 && (node_mem == '136.8 GB' || node_mem == '141.7 GB')) {
            includeConfig "${projectDir}/config/midmem.config"
            }
        else if (node_cpus == 64 && (node_mem == '950 GB' || node_mem == '1007.9 GB')) {
            includeConfig "${projectDir}/config/execute.config"
            }
        else {
            throw new Exception('ERROR: System resources not as expected, unable to assign resources.')
            }
        }

    setup = {
        methods.set_output_dir()
        methods.set_env()
        methods.set_process()
        methods.set_timeline()
        methods.set_trace()
        methods.set_report()
        methods.set_docker_sudo()

        if (!params.containsKey('check_node_config') || params.check_node_config) {
            methods.set_node_config()
            }
        else {
            System.out.println "WARNING: check_node_config is false. This job will not configure process CPU and memory parameters, which may cause unexpected run times."
            }
        }
    }
